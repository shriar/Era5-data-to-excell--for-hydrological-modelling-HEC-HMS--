{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extracting_ERA5Data():\n",
    "    def __init__(self, path_nc, path_basin):\n",
    "        self.ds = xr.open_dataset(path_nc, decode_times=True)\n",
    "        self.grid_size = 0.25\n",
    "        self.path_basin = path_basin\n",
    "        self.timestep = self.ds.time.shape[0]\n",
    "        self.datetime_series = pd.Series(self.ds['time'])\n",
    "        # self.datetime_series = pd.Series(self.ds['time'][0:self.timestep])\n",
    "        self.datetime_series = np.array(self.datetime_series, dtype=object)\n",
    "        self.longitudes = self.ds[\"longitude\"].values\n",
    "        self.len_long = len(self.longitudes)\n",
    "        self.latitudes = self.ds[\"latitude\"].values\n",
    "        self.len_lat = len(self.latitudes)\n",
    "        self.num_grid = self.len_lat * self.len_long\n",
    "\n",
    "        self.gdf = gpd.read_file(self.path_basin)\n",
    "        self.geometries = self.gdf[\"geometry\"]\n",
    "        self.subbasin_name = self.gdf[\"name\"]  \n",
    "        # it may not match for all type of basins. you may need to change this.\n",
    "\n",
    "    # finding all the point locations that are within  the boundaries\n",
    "    def find_center_of_data_grid(self):\n",
    "        points = []\n",
    "        for lon in self.longitudes:\n",
    "            for lat in self.latitudes:\n",
    "                points.append((lon, lat))\n",
    "        lat_long = np.array(points).reshape((self.len_lat, self.len_long, 2))\n",
    "        return lat_long\n",
    "    \n",
    "    # extracting point from basin shape file (just used for plotting)\n",
    "    def extract_points_of_basins(self):\n",
    "        points_of_shape_file = np.empty((0,  2))\n",
    "        number_of_points_in_each_polygon = []\n",
    "        for geometry in self.geometries:\n",
    "            if geometry.geom_type == 'Polygon':\n",
    "                points_one_polygon = np.array(geometry.exterior.coords[:])\n",
    "                number_of_points_in_each_polygon.append(len(points_one_polygon))\n",
    "                points_of_shape_file = np.concatenate((points_of_shape_file, points_one_polygon), axis=0)\n",
    "                \n",
    "            elif geometry.geom_type == 'MultiPolygon':\n",
    "                # number_points_multi_polygon = []\n",
    "                for polygon in geometry.geoms:\n",
    "                    points_one_polygon = np.array(polygon.exterior.coords[:])\n",
    "                    # number_points_multi_polygon.append(len(points_one_polygon))\n",
    "                    points_of_shape_file = np.concatenate((points_of_shape_file, points_one_polygon), axis=0)\n",
    "\n",
    "                    number_of_points_in_each_polygon.append(len(points_one_polygon))\n",
    "                    # number_of_points_in_each_polygon.append(sum(number_points_multi_polygon))\n",
    "\n",
    "        number_of_points_in_each_polygon = [sum(number_of_points_in_each_polygon[:i+1]) for i in range(len(number_of_points_in_each_polygon))]  # cumulative sum\n",
    "        return number_of_points_in_each_polygon, points_of_shape_file\n",
    "    \n",
    "    # creating rectangle around the data points\n",
    "    def create_rect(self, point, diff):\n",
    "        return (\n",
    "            [point[0] - diff, point[1] + diff],\n",
    "            [point[0] + diff, point[1] + diff],\n",
    "            [point[0] + diff, point[1] - diff],\n",
    "            [point[0] - diff, point[1] - diff],\n",
    "        )\n",
    "\n",
    "    # here is the flaw. I have increase the coordinate by 0.25 degree, because grid size is 0.25 degree. but in other cases grid may not 0.25 degree. \n",
    "    # And also there may be irregular grid size. \n",
    "    # And also this portion of the code should be re-considered later.  \n",
    "    # this is the easiest code. But this is where i was stuck. I wonder why?\n",
    "    def create_rect_around_c_data(self):\n",
    "        lat_long = self.find_center_of_data_grid()\n",
    "        rects = []\n",
    "        for point in lat_long.reshape(-1, 2):\n",
    "            rects.append(list(self.create_rect(point, self.grid_size / 2)))\n",
    "        rects = np.array(rects)\n",
    "        rects = rects.reshape(self.len_lat, self.len_long, 4, 2)\n",
    "        return rects\n",
    "    \n",
    "    def find_area_between_polygon(self, polygon1, polygon2):\n",
    "        intersection = polygon1.intersection(polygon2)\n",
    "        return intersection.area\n",
    "    \n",
    "\n",
    "    # take the first one from the expver. if the first one is nan, take the second. if both is nan, then take the nan.\n",
    "    def get_first_non_nan_expver(self, data):\n",
    "        expver_data = data[:, :, :, 0]\n",
    "        nan_mask = np.isnan(expver_data)\n",
    "        expver_values = np.where(nan_mask, data[:, :, :, 1], expver_data)\n",
    "        return expver_values\n",
    "    \n",
    "    # this function looks very big. i should try to divide this into some component.\n",
    "    def extract_variable(self, var_name, type):\n",
    "        rects = self.create_rect_around_c_data()\n",
    "        one_basin_var = np.zeros((self.timestep, 1))\n",
    "        all_basins_var = self.datetime_series.reshape((-1, 1))\n",
    "\n",
    "        if var_name == 't2m':\n",
    "            var_matrix = self.ds[var_name].values - 273.15\n",
    "        elif var_name == 'tp' or var_name == 'sd' or var_name == 'e':\n",
    "            var_matrix = self.ds[var_name].values * 1000  \n",
    "        else:\n",
    "            var_matrix = self.ds[var_name].values\n",
    "\n",
    "\n",
    "        if len(var_matrix.shape) == 4:\n",
    "            # var_matrix = var_matrix[~np.isnan(var_matrix)].reshape((self.timestep, self.len_lat, self.len_long)) # remove all the nan values and reduced the expver dimension\n",
    "            var_matrix = self.get_first_non_nan_expver(var_matrix)\n",
    "            \n",
    "        # find the var of all the sub-basins\n",
    "        for geometry, name in zip(self.geometries, self.subbasin_name):\n",
    "            print(name)\n",
    "        # find the var of one sub-basin\n",
    "            for i in range(self.len_lat):\n",
    "                for j in range(self.len_long):\n",
    "                    one_var_values = var_matrix[:, i, j].reshape(-1, 1)\n",
    "\n",
    "                    one_rect = Polygon(rects[i, j])\n",
    "                    rectangle_area = one_rect.area\n",
    "\n",
    "                    intersection_area = self.find_area_between_polygon(geometry, one_rect)\n",
    "                    weight = (intersection_area / rectangle_area)\n",
    "                    if type == \"average\":\n",
    "                        if weight == 0:\n",
    "                            weight = 0\n",
    "                        else: \n",
    "                            weight = 1\n",
    "                    \n",
    "                    weighted_var = weight * one_var_values\n",
    "                    one_basin_var = np.concatenate((one_basin_var, weighted_var.reshape(-1, 1)), axis=1)\n",
    "\n",
    "            if type == \"sum\":\n",
    "                one_basin_var = np.sum(one_basin_var, axis=1).reshape(-1, 1)\n",
    "            elif type == \"average\":\n",
    "                zeros_count = (one_basin_var == 0).sum(axis=1).reshape(-1, 1) - 1\n",
    "                # print(zeros_count)\n",
    "                one_basin_var = np.sum(one_basin_var, axis=1).reshape(-1, 1)/(self.num_grid - zeros_count)  # summing for all the grid\n",
    "            else:\n",
    "                raise ValueError(\"Type should be sum or average\")\n",
    "            # if var_name == 't2m' or var_name == 'rsn':\n",
    "            #     zeros_count_per_row = (one_basin_var == 0).sum(axis=1).reshape(-1, 1) - 1\n",
    "            # else:\n",
    "            #     zeros_count_per_row = 1\n",
    "            # print(one_basin_var.shape[1])\n",
    "            # print(one_basin_var.shape, zeros_count_per_row.shape)\n",
    "            # one_basin_var = np.sum(one_basin_var, axis=1).reshape(-1, 1)/(self.num_grid - zeros_count_per_row)  # summing for all the grid\n",
    "            all_basins_var = np.concatenate((all_basins_var, one_basin_var), axis=1) \n",
    "            one_basin_var = np.zeros((self.timestep, 1)) #resetting the initial values\n",
    "\n",
    "        column_name = ['Date'] + self.subbasin_name.tolist()\n",
    "        df = pd.DataFrame(all_basins_var, columns=column_name)\n",
    "        return df\n",
    "\n",
    "    # this function average for the whole netcdf file. i use this for temparature. because extracting temparature using preceding function does not look very accurate.\n",
    "    def extract_by_avering(self, var_name):\n",
    "        var = self.ds[var_name].values\n",
    "        var = self.get_first_non_nan_expver(var)\n",
    "        if var_name == 't2m':\n",
    "            var_matrix = var - 273.15 \n",
    "        elif var_name == 'tp' or var_name == 'sd' or var_name == 'e':\n",
    "            var_matrix = var * 1000  \n",
    "        else:\n",
    "            var_matrix = var\n",
    "\n",
    "        var_matrix = np.average(var_matrix, axis=(1, 2)).reshape(-1, 1)\n",
    "\n",
    "        data = {'Date': self.datetime_series, var_name: var_matrix.flatten()}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    def create_plot(self, n_point=None, n_subBasin =None):\n",
    "        rects = self.create_rect_around_c_data()\n",
    "        number_of_points_in_each_polygon, points_of_shape_file = self.extract_points_of_basins()\n",
    "        lat_long = self.find_center_of_data_grid()\n",
    "        \n",
    "        plt.figure(figsize=(10,  5))\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        if n_point != None:\n",
    "            # plotting of the data points\n",
    "            x, y = lat_long[n_point[0], n_point[0], 0], lat_long[n_point[1], n_point[1], 1]\n",
    "            plt.scatter(x, y)\n",
    "            # plotting of the rectangles\n",
    "            x, y = rects[n_point[0], n_point[0], :, 0], rects[n_point[1], n_point[1], :, 1]\n",
    "            plt.scatter(x, y)\n",
    "        else:\n",
    "            # plotting of the data points\n",
    "            x, y = lat_long[:, :, 0], lat_long[:, :, 1]\n",
    "            plt.scatter(x, y)\n",
    "            # plotting of the rectangles\n",
    "            x, y = rects[:, :, :, 0], rects[:, :, :, 1]\n",
    "            plt.scatter(x, y)\n",
    "\n",
    "            \n",
    "\n",
    "        # plotting of the sub-basins\n",
    "        if n_subBasin == None:\n",
    "            for i, n_points in enumerate(number_of_points_in_each_polygon):\n",
    "                if i == 0:\n",
    "                    x_p, y_p = points_of_shape_file[:n_points, 0], points_of_shape_file[:n_points, 1]\n",
    "                else:\n",
    "                    x_p, y_p = (points_of_shape_file[number_of_points_in_each_polygon[i-1]:n_points, 0], \n",
    "                                points_of_shape_file[number_of_points_in_each_polygon[i-1]:n_points, 1])\n",
    "                    \n",
    "                plt.plot(x_p, y_p, \n",
    "                        #  label=f\"{i +  1}\"\n",
    "                        )\n",
    "        else:\n",
    "                m, n = number_of_points_in_each_polygon[n_subBasin], number_of_points_in_each_polygon[n_subBasin-1]\n",
    "                x_p, y_p = (points_of_shape_file[n:m, 0], \n",
    "                            points_of_shape_file[n:m, 1])\n",
    "                plt.plot(x_p, y_p, \n",
    "                        #  label=f\"{i +  1}\"\n",
    "                        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting variable to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaporation and Precipitation  -- -- \n",
    "test1 = Extracting_ERA5Data(\n",
    "    # r\"combined.nc\",  # location of netcdf file\n",
    "    r\"combined_dataset.nc\",  # location of netcdf file\n",
    "    r\"evapotranspiration.shp\" # location of basin shape file \n",
    ")\n",
    "\n",
    "# tp = test1.extract_variable('tp', type='sum') # unit mm\n",
    "# t2m_wgt = test1.extract_variable('t2m', type='average') # unit C\n",
    "# e = test1.extract_variable('e', type='sum') # unit mm\n",
    "# sd = test1.extract_variable('sd', type='sum')  # unit mm\n",
    "# rsn = test1.extract_variable('rsn', type='average') # unit kg/m-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For combining multiple variable in one excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for combining multiple variable in one excell\n",
    "with pd.ExcelWriter('output2.xlsx') as writer:\n",
    "    # tp.to_excel(writer, sheet_name='tp(mm)', index=False)\n",
    "    # t2m.to_excel(writer, sheet_name='t2m(C)', index=False)\n",
    "    # e.to_excel(writer, sheet_name='e(mm)', index=False)\n",
    "    # sd.to_excel(writer, sheet_name='sd(mm)', index=False)\n",
    "    # rsn.to_excel(writer, sheet_name='rsn(kg/m-3)', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.create_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving to excell\n",
    "# df = pd.concat([tp], ignore_index=True)\n",
    "\n",
    "\n",
    "# start_date = '2019-01-01 00:00:00'\n",
    "# end_date = '2022-01-01 00:00:00'\n",
    "# filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "# # filtered_df\n",
    "\n",
    "\n",
    "# filtered_df = df\n",
    "\n",
    "# with pd.ExcelWriter('output.xlsx', mode='w') as writer:\n",
    "#     tp.to_excel(writer, sheet_name='tp', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2m = test1.extract_by_avering('t2m')\n",
    "# plt.figure(figsize=(10,  5))\n",
    "# plt.plot(t2m['Date'], t2m['t2m'])\n",
    "# plt.title('Temparature vs Date')\n",
    "# plt.xlabel('DateTime')\n",
    "# plt.ylabel('Temparature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 3050\n",
    "# df_21_24[n:n+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,  5))\n",
    "# plt.plot(df_21_24['Date'], df_21_24['Subbasin-1'])\n",
    "# plt.title('Precipitation vs Date')\n",
    "# plt.xlabel('DateTime')\n",
    "# plt.ylabel('Precipitation')\n",
    "\n",
    "# start_date = '2021-01-01 00:00:00'\n",
    "# end_date = '2022-01-01 00:00:00'\n",
    "# filtered_df = df_21_24[(df_21_24['Date'] >= start_date) & (df_21_24['Date'] <= end_date)]\n",
    "# plt.figure(figsize=(10,  5))\n",
    "# plt.plot(df_21_24['Date'], df_21_24['Subbasin-1'])\n",
    "# plt.title('Evaporation vs Date')\n",
    "# plt.xlabel('DateTime')\n",
    "# plt.ylabel('Evaporation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2 = Extracting_ERA5Data(\n",
    "#     r\"C:\\Users\\User\\Desktop\\HEC-HMS\\Hec-Hms Project\\parameter\\17-20.nc\",\n",
    "#     r\"C:\\Users\\User\\Desktop\\hechms\\Sub-Basin(WGS).shp\"\n",
    "# )\n",
    "# df_17_20 = test2.extract_variable('tp')\n",
    "# test1.create_plot(n_point=[5, 2], n_subBasin=1)\n",
    "# test1.create_plot(n_point=[5, 2], n_subBasin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
